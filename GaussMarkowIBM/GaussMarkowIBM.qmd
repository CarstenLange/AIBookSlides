---
title: "Gauss Markow"
subtitle: "Linearity, no perfect multicollinearity, strict exogeneity, no heteroscedacisity, noautocorrelation"
format: 
  revealjs:
    multiplex: true
    code-fold: false
    scrollable: true
    echo: true
    incremental: false
    smaller: false
---

## What Will You Learn {.scrollable .smaller}

-   What are the Gauss Markov assumptions?

-   What means *BLUE* (**B**est **L**inear **U**nbiased Model)?

-   How to test if Gauss Markov assumptions are violated?

-   What are the consequences if Gauss Markov assumptions are violated?

-   Remedies to use when Gauss Markov assumptions are violated?

## Gauss Markow Assumptions

-   Linearity

-   No perfect Multicollinearity,

-   Strict Exogeneity (errors are not correlated with any predictor variable's values)

-   no heteroscedacisity

-   no autocorrelation (errors are not correlated with their pressors; applies only when observations have a "natural order")

## wage2 Data from Wooldridge --- Data Enginering

```{r}
#| output-location: fragment
#| code-line-numbers: "1-3|4-8|10"
library(tidymodels)
library(janitor)
library(wooldridge)
DataWage=wage2 |> 
         clean_names("upper_camel") |> 
         select(Wage,LogWage=Lwage, Educ, Tenure, RaceBl=Black, Feduc, Meduc) |> 
         mutate(ParEdu=pmax(Feduc,Meduc)) |> 
         drop_na(ParEdu) 

cat("Mean monthly wage:",mean(DataWage$Wage))
```

. . .

```{r}
#| eval: false
library(SmartEDA)
ExpReport(DataWage, op_file = "EdaDataWage2")
```

[Click to open: EdaDataWage2.html](EdaDataWage2.html "Click")

## Linearity

**Not fulfilled:** Coefficients $(\beta s)$ are biased and inconsistent:"

**Identify:** Visual inspection of regression and residuals.

**Remedy:** Use logarithms or polynomials (such as squares) on data.

## Linearity

```{r}
#| code-fold: true
DataPlot=DataWage |> 
         select(LogWage,Educ) |> 
         group_by(Educ) |> 
         mutate(CondMean=mean(LogWage))

ggplot(DataPlot, aes(y=LogWage, x=Educ))+
  geom_point(alpha=0.2)+
  geom_smooth(method="lm", se=FALSE)+
  geom_point(aes(x=Educ, y=CondMean), color="red", size=7)+
  scale_x_continuous(breaks = c(0:100))
  
```

## Multi Collinearity (Overview) {.smaller}

**Not fulfilled (perfect multicolinearity):** Coefficients $(\beta s)$ cannot be calculated"

**Not fulfilled (strong multicolinearity):** 

- Coefficients $(\beta s)$ are biased and inconsistent. 

- However, predictions are not.

- Coefficients $(\beta s)$ are sensitive to small changes in data.

**Identify:** VIF between an independent variables $i$ regressed on all other variables should be less than $10$ (some authors use less than 5):

$$VIF=\frac{1}{1-R^2_{i}}$$




**Remedy:** 

- Do nothing

- Eliminate variable(s) that are correlated with others step wise (!)

- Others

## Multi Collinearity (Example) {.smaller}



Assume we have two variables for education. $Edu$ measures the years of education, but $EducMod$ counts high school dropouts as 12 years and does not consider graduate studies and thus cuts off EducMod$ at 16 years.

```{r}
#| code-line-numbers: "1-8|9,10|12-14"
#| output-location: slide
library(tidymodels)
library(janitor)
library(wooldridge)
DataWage=wage2 |> 
         clean_names("upper_camel") |> 
         select(Wage,LogWage=Lwage, Educ, Tenure, RaceBl=Black, Feduc, Meduc) |> 
         mutate(ParEdu=pmax(Feduc,Meduc)) |> 
         drop_na(ParEdu) |> 
         mutate(EducMod=ifelse(Educ<12, 12, Educ)) |> 
         mutate(EducMod=ifelse(Educ>16, 16, EducMod))

ggplot(DataWage, aes(x=Educ, y=EducMod))+
      geom_point()+
      geom_smooth(method = "lm", se=FALSE)
```

## Multi Collinearity (Regression Examples) {.smaller}

```{r}
#| code-line-numbers: "1|2|3|4"
ModelWage0=lm(LogWage~Educ+Tenure+RaceBl, DataWage)
set.seed(123)
ModelWage1=lm(LogWage~Educ+EducMod+Tenure+RaceBl, DataWage |> sample_n(500))
ModelWage2=lm(LogWage~Educ+EducMod+Tenure+RaceBl, DataWage |> sample_n(500))
```

::: {.fragment}
```{r}
summary(ModelWage0)
```
:::

::: {.fragment}
```{r}
summary(ModelWage1)
```
:::

::: {.fragment}
```{r}
summary(ModelWage2)
```
:::

::: {.fragment}
```{r}
library(car)
vif(ModelWage1)
vif(ModelWage2)
```
:::

::: {.fragment}
```{r}
ModelWage00=lm(LogWage~EducMod+Tenure+RaceBl, DataWage)
summary(ModelWage00)
```
:::
## Endogenity of Education

```{r}
#| output-location: slide
library(ggdag)
set.seed(123)
dagify(Wage~Educ+Ability+RaceBl,
       Educ~Ability,
       Educ~ParEdu,
       Educ~RaceBl) |> ggdag(node_size = 22)
       
```

## Endogeneity (Correlation with the errors) --- Simple Model

```{=tex}
$$\widehat{Wage}= \beta_1 Educ + \beta_2 RaceBl +\beta3$$
```


## Endogeneity (Correlation with the errors) --- Simple Model

```{r}
#| output-location: fragment
#| code-line-numbers: "1|2"
ModelWageEdu=lm(LogWage~RaceBl+Educ,DataWage)
summary(ModelWageEdu)
```

## Endogeneity (Correlation with the errors) --- IV Model 

### Instrumen: $ParEduc$

```{r}
#| echo: false
set.seed(123)
dagify(Wage~Educ+Ability+RaceBl,
       Educ~Ability,
       Educ~ParEdu,
       Educ~RaceBl) |> ggdag(node_size = 22)
```

## Endogeneity (Correlation with the error) --- IV Model 

### (Instrument: ParEduc)

```{=tex}
$$
\widehat{Educ}&=& \alpha_1 ParEdu + \alpha_2 RaceBl +\beta3
$$
```

. . . 

```{=tex}
$$
\widehat{Wage}= \beta_1 \widehat{Educ} + \beta_2 RaceBl +\beta3
$$
```

## Endogeneity (Correlation with the error) --- IV Model (

### Instrumen: $ParEdu$


```{r}
#| output-location: fragment
#| code-line-numbers: "1|2|3"
library(AER)
ModelWageEdiIV=ivreg(LogWage~RaceBl+Educ|RaceBl+ParEdu, data=DataWage)
summary(ModelWageEdiIV)
```
## Heteroscedasticity 

### Overview

**Not fulfilled:** Standard errors and thus P values are incorrect.

**Identify:** Visual inspection of residuals. White test.

**Remedy:** White robust standard errors

## Heteroscedasticity 

### No Heteroscedasticity in IV Wage Model

```{r}
#| code-fold: true
DataPlot=augment(ModelWageEdiIV)

ggplot(DataPlot, aes(x=LogWage, y=.resid))+
  geom_point(alpha=0.2)
  
```

## Heteroscedasticity 

### Some Heteroscedasticity in House Model (Sqft, Grade, Waterfront)

```{r}
library(rio);library(janitor);library(tidymodels)
DataHouses =
import("https://ai.lange-analytics.com/data/HousingData.csv") |>
clean_names("upper_camel") |>
select(Price, Sqft=SqftLiving, Grade, Waterfront)

ModelHouses=lm(Price~., DataHouses)

DataPlot=augment(ModelHouses) |> 
         mutate(Category=case_when(Price<500000~1,
                                  Price<1000000~2,
                                  Price<1500000~3,
                                  Price<2000000~4,
                                  Price<2500000~5,
                                  Price<3000000~6,
                                  TRUE~7)) |>
         group_by(Category) |>  
         mutate(TwoSDHigh=mean(.resid)+2*sd(.resid)) |> 
         mutate(TwoSDLow=mean(.resid)-2*sd(.resid))

ggplot(DataPlot)+
  geom_point(aes(x=Price, y=.resid, color="Residuals"), alpha=0.2)+
  geom_point(aes(x=Price, y=TwoSDLow, color="Mean - 2 SD"))+
  geom_point(aes(x=Price, y=TwoSDHigh, color="Mean + 2 SD"))+
  scale_color_manual(values = c("Residuals" = "black", "Mean - 2 SD" = "orange", "Mean + 2 SD" = "red")) +
  scale_x_continuous(limits = c(0,3000000))+
  scale_y_continuous(limits = c(-2000000,3000000))
  

 
```

