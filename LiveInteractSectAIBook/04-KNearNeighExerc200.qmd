---
title: "Interactive Exercises for k-Nearest Neighbors: Predict Wine Color"
subtitle: "Companion Exercises for [Practical Machine Learning with R](https://ai.lange-analytics.com)"

author:
  - name: "Carsten Lange"
    email: "clange@cpp.edu"
    affiliation: "Professor of Economics, Cal Poly, Pomona"
format: 
  live-html:
    number-sections: true

webr:
  packages: ['dplyr', 'rsample', 'janitor',  'recipes', 
             'yardstick','parsnip','workflows', 'kknn'] # Auto-install packages in the browser

engine: knitr
---

{{< include .././_extensions/r-wasm/live/_knitr.qmd >}}
{{< include .././_extensions/r-wasm/live/_gradethis.qmd >}}

:::: {.content-visible when-runtime="loading"}
::: {.callout-note}
## Please be Patient: Loading R Environment
The interactive R environment and the required packages must be loaded in your browser. This typically takes 1â€“2 minutes. You can monitor the progress in the bottom-right corner. 

When everything is loaded, you get a **"Ready to roll"** message below.

Thank you for your patience!
:::
::::

```{webr}
#| auto-run: true
#| echo: false
cat("\033[1;32mReady to roll\033[0m\n")
```


**Libraries** already loaded in the background:

- *tidyverse*
- *tidymodels*
- *kknn*

**Data already loaded in the background:**

- `DataWine`
- Source: "https:///econ.lange-analytics.com/RData/Datasets/WineData.csv"

In what follows, you will develop your own *k-Nearest Neighbors* model to predict the color of wines based on chemical properties. In contrast to the previous section, you will extend the analysis to use all chemical properties available in the wine dataset.

Below you can see all variables available in the wine dataset. The first variable $WineColor$ is the outcome variable, followed by the predictor variables that indicate the chemical properties of a wine. The  variable $Quality$ which reflect how consumers rated the quality of the wines and which is in the original dataset, is omitted. This variable is not a chemical property and is likely irrelevant for predicting a wine's color:

```{webr}
#| label: ex_all
#| include: false

set.seed(876)

DataWine = read.csv("https:///econ.lange-analytics.com/RData/Datasets/WineData.csv") |> 
           clean_names("upper_camel") |> 
           select(-Quality) |> 
           rename(Sulfur=TotalSulfurDioxide) |> 
           mutate(WineColor=as.factor(WineColor))

Split7030=initial_split(DataWine, prop=0.7, strata=WineColor)

DataTrain=training(Split7030)

DataTest=testing(Split7030) 

RecipeWine=recipe(WineColor~., data=DataTrain) |>
           step_naomit() |> 
           step_normalize(all_predictors()) 

ModelDesignKNN=nearest_neighbor(neighbors=4, weight_func="rectangular") |>
               set_engine("kknn") |> 
               set_mode("classification")

WFModelWine=workflow() |> 
            add_recipe(RecipeWine) |>
            add_model(ModelDesignKNN) |> 
            fit(DataTrain)

DataTestWithPred=augment(WFModelWine, DataTest)
```

```{webr}
#| exercise: ex_0
#| exercise.setup: ex_all
#| autorun: true
#| runbutton: false
head(DataWine)
```

## Exercise 1 

The code block below uses the already loaded wine dataset (`DataWine`). The variable $WineColor$ was coded as a `factor` data type as required by the *k-Nearest Neighbors* algorithm.



**Now it is your turn:** After the random number generator has been initialized. Please complete the two commands that extract training and testing data from the split to assign them to the data frames `DataTrain` and `DataTest`.

```{webr}
#| exercise: ex_1
#| exercise.setup: ex_all
set.seed(876)
Split7030=initial_split(DataWine, prop=0.7, strata=WineColor)

DataTrain=______(______)
DataTest=______(______)
```

::: { .hint exercise="ex_1"}
**Here is a hint:**

The command to extract the *training data* from the initial split is called `training()`. 
The one for the *testing data* is called `testing()`.

The initial split is stored in the R object `Split7030`. 
The latter includes the data frame `DataWine` together 
with an indicator for each observation, if it 
belongs to the *training data* or the `testing data`.

`Split7030` is the only argument needed in the commands `training()` and `testing()`.
:::

::: {.solution exercise="ex_1"}
**Here is the solution:**

```{webr}
#| exercise: ex_1
#| solution: true
set.seed(876)
Split7030=initial_split(DataWine, prop=0.7, strata=WineColor)

DataTrain=training(Split7030) #<1>
DataTest=testing(Split7030)  #<2>
```                                

1. The commands `training()`  generates   the  *training data*. `Split7030` determines which observations from `DataWine` are sorted into the *training data*
2. The commands `testing()`  generates   the  *testing data*. `Split7030` determines which observations from `DataWine` are sorted into the *testing data*
:::

```{webr}
#| exercise: ex_1
#| check: true
gradethis::grade_this_code()
```

## Exercise 2 

This exercise requires some preparation. By **executing** the code block below **without editing**, you will create the **recipe** and the results will be saved into the *R* object `RecipeWine`. The command `tidy` outputs the recipe as a data frame that is easy to read:

```{webr}
#| exercise: ex_2prep1
#| exercise.setup: ex_all
RecipeWine=recipe(WineColor~., data=DataTrain) |> 
           step_naomit() |> 
           step_normalize(all_predictors())
tidy(RecipeWine)
```

You also need to define the **model-design**. When you execute the commands below **without editing** the *model-design*  will be created and saved into the *R* object `ModelDesignKNN`:

```{webr}
#| exercise: ex_2prep2
#| exercise.setup: ex_all
ModelDesignKNN=nearest_neighbor(neighbors=4, 
                                weight_func="rectangular") |>
               set_engine("kknn") |> 
               set_mode("classification")

ModelDesignKNN
```

**Now you will work with code:** You are  tasked with adding the *recipe* and the *model-design* to a **workflow** and then fitting the workflow to the training data. Note that the *recipe* `RecipeWine`, the *model-design* `ModelDesignKNN`, and the data frame `DataTrain` have already been loaded in the background. Please complete the code block below and execute it.

```{webr}
#| exercise: ex_2
#| exercise.setup: ex_all
WFModelWine=workflow() |> 
            add_recipe(______) |>
            add_model(______) |> 
            fit(______)

WFModelWine
```

::: {.hint exercise="ex_2"}
**Here is a hint:**

The *recipe* (`RecipeWine`) and the *model-design* (`ModelDesignKNN`) from the previous exercises   have been loaded in the background. They  need to be **added** to the *workflow*.

To **fit the workflow** and make it a *fitted workflow model*, we
use the `fit()` command. We always use the *training data* to *fit* a model (in this case  `DataTrain`)
:::

::: {.solution exercise="ex_2"}
**Here is the solution:**

```{webr}
#| exercise: ex_2
#| solution: true
WFModelWine=workflow() |> #<1>
            add_recipe(RecipeWine) |>
            add_model(ModelDesignKNN) |> 
            fit(DataTrain)  

WFModelWine #<2>
```

1. This pipe adds the *recipe* and the *model-design* to the *workflow model* and fits it to the *training data*.
2. Here the fitted workflow is printed out.
:::

```{webr}
#| exercise: ex_2
#| check: true
gradethis::grade_this_code()
```

## Exercise 3

Because the workflow model is now fitted to the training data, we can use the *fitted workflow model*  (`WFModelWine`) for predictions. 

Instead of using the `predict()` command, we  use the more comprehensive `augment()` command, which predicts $WineColor$ based on the predictor variables from the *testing dataset* and then adds the predictions as a new variable named $.pred\_class$ to the  *testing dataset* (`DataTest`). The complete result is saved in the *R* object `DataTestWithPred`.

After the *R* object `DataTestWithPred` is created, it contains the predictions (`estimate`) for the wine color and also the true wine color (`truth`). The latter is stored in variable $WineColor$, we can use it as the data argument for metrics commands. An example is the `conf_mat()` command that generates a confusion matrix. 

Please complete the code below accordingly to generate the prediction data frame 'DataTestWithPred' and the *confusion matrix*:

```{webr}
#| exercise: ex_3
#| exercise.setup: ex_all
DataTestWithPred=augment(______, DataTest)
conf_mat(DataTestWithPred, truth=WineColor, estimate=______)
```

::: { .hint exercise="ex_3"}
**Here is a hint:**

The `augment()` command uses the fitted workflow `WFModelWine` generates the predictions based on the *testing dataset* and *augments* the *testing dataset* with a new column `.pred_class` which hold the predictions.

To create  the confusion matrix you have to provide the column with the estimate (the predictions) called `pred_class` which will be compared to the true wine color (`WineColor`)
:::

::: {.solution exercise="ex_3"}
**Here is the solution:**

```{webr}
#| exercise: ex_3
#| solution: true
DataTestWithPred=augment(WFModelWine, DataTest)   #<1>
conf_mat(DataTestWithPred, truth=WineColor, estimate=.pred_class) #<2>
```

1. Augments the training dataset with the predictions. The related column is called `.pred_class`
2. Compares the *truth* in the column `WineColor` to the predictions in the column `.pred_class` and generates the *confusion matrix*.
:::

```{webr}
#| exercise: ex_3
#| check: true
gradethis::grade_this_code()
```

## Exercise 4


A first glance at the diagonal elements of the confusion matrix above already indicates a very good result.

The `tidymodels` package can help you to calculate metrics such as *accuracy*, *sensitivity*, and *specificity*. Instead of calculating these metrics separately you can streamline the process by creating a *metric set* first.\index{metric\_set()}

In the code block below, the command `metric_set()` creates a new command that we name `MetricsWine` (you can choose a different name if you like).

The newly created command `MetricWine()` can be used similarly to the `conf_mat()` command, but instead of creating a confusion matrix, it creates all the metrics previously specified with `metric_set()` simultaneously. This saves you some typing effort.

Give it a try with the code block below:

```{webr}
#| exercise: ex_4
#| exercise.setup: ex_all
MetricsWine=metric_set(accuracy, sensitivity, specificity)
MetricsWine(DataTestWithPred, truth=______, estimate=______)
```

::: { .hint exercise="ex_4"}
**Here is a hint:**
The command `MetricsWine()`  was generated in the first line of code. It requires --- like confusion matrix command --- three arguments:

1. The data frame that contains the predictions and the true values.
2. The column name from that dataset containing the true values (`truth`).
2. TThe column name from  that dataset containing the predictions (`estimate`).
:::

::: {.solution exercise="ex_4"}
**Here is the solution:**

```{webr}
#| exercise: ex_4
#| solution: true
MetricsWine=metric_set(accuracy, sensitivity, specificity) #<1>
MetricsWine(DataTestWithPred, truth=WineColor, estimate=.pred_class) #<2>
```

1. Creates a new command that simultaneously calculates *accuracy*, *sensitivity*, and *specificity*.
2. Provides the data frame that contains the predictions as well as the true values.
:::

```{webr}
#| exercise: ex_4
#| check: true
gradethis::grade_this_code()
```

As the confusion matrix and the three metrics above confirm, we reached an almost perfect prediction quality.

Try changing the arguments in the `metric_set()` command to different metrics and see what happens.


