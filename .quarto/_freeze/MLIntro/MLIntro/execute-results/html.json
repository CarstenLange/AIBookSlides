{
  "hash": "75dd2d83b74cc493d69723fbb894e134",
  "result": {
    "markdown": "---\ntitle: \"Intro to Machine Learning\"\nsubtitle: \"Types, Tasks, Terminology\"\nformat: \n  revealjs:\n    code-fold: true\n---\n\n\n# Introduction to Machine Learning\n\n## What is What?\n\n-   Artificial Intelligence (AI),\n-   Machine Learning,\n-   Deep Learning\n-   Big Data\n\n## What is What?\n\n![Types of AI](Images/TypesOfAI1.png)\n\n## What is What? {auto-animate=\"true\"}\n\n![Types of AI](Images/TypesOfAI2.png)\n\n## What is What?\n\n![Types of AI](Images/TypesOfAI3.png)\n\n## What About Big Data\n\n## What About Big Data\n\n-   Big Data is not a category of learning. It is a category of data!!!\n-   Two common definitions\n    -   Laymen: Many records (thousands?, millions?, billions?)\n    -   Experts: So many records that they do not fit in the memory of one computer.\n        -   At least billions of records.\n        -   Requires distributed computing.\n\n## Three Applications of Machine Learning {auto-animate=\"true\"}\n\n::: nonincremental\n-   Regression\n-   Classification\n-   Cluster\n:::\n\n## Three Applications of Machine Learning {.smaller auto-animate=\"true\"}\n\n::: nonincremental\n-   Regression\n    -   Outcome variable is continuous\n    -   We try to predict a numerical value\n-   Classification\n-   Cluster\n:::\n\n## Three Applications of Machine Learning {auto-animate=\"true\"}\n\n::: nonincremental\n-   Regression\n-   Classification\n-   Cluster\n:::\n\n## Three Applications of Machine Learning {.smaller auto-animate=\"true\"}\n\n::: nonincremental\n-   Regression\n-   Classification\n    -   Outcome variable is categorial\n    -   Most of the times 2 categories such as:\n        -   Yes/No\n        -   Red Wine/White Wine\n        -   True/False\n        -   often represented as dummies: 1/0\n    -   Sometimes more than two catogories (ordered or unordered):\n        -   good, fair, bad (ordered)\n        -   red, blue, green (unordered)\n        -   strongly agree, agree, disagree, strongly disagree (ordered)\n-   Cluster\n:::\n\n## Three Applications of Machine Learning {auto-animate=\"true\"}\n\n::: nonincremental\n-   Regression\n-   Classification\n-   Cluster\n:::\n\n## Three Applications of Machine Learning {.smaller auto-animate=\"true\"}\n\n::: nonincremental\n-   Regression\n-   Classification\n-   Cluster\n    -   Sorting observations into a number of groups based on feature variables.\n    -   Groups are as homogenous inside as possible.\n    -   Groups are as diverse between groups (when comparing groups)\n:::\n\n## Three Applications of Machine Learning {auto-animate=\"true\"}\n\n::: nonincremental\n-   Regression\n-   Classification\n-   Cluster\n:::\n\n## Terminolgy {.smaller}\n\nFirst 3 Observations (records) of the Housing Dataset (to predict house prices)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rio);library(tidyverse)\nDataHousing =\n  import(\"https://lange-analytics.com/AIBook/Data/HousingData.csv\") %>% \n  select(Price=price, Sqft=sqft_living, Bedrooms=bedrooms,Waterfront=waterfront)\nprint(DataHousing[1:3,])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Price Sqft Bedrooms Waterfront\n1 221900 1180        3         no\n2 538000 2570        3         no\n3 180000  770        2         no\n```\n:::\n:::\n\n\nTidy data:\n\n-   Observations (synonym: records) are in the rows.\n-   Variables (synonym: features) are in the columns.\n-   Variable names (column names) are in the first row.\n-   Data are in individual cells (and they form vectors; column names can be interpreted as vector names).\n\n## Terminolgy {.smaller}\n\n::: panel-tabset\n### Main\n\nFirst 3 Observations (records) of the Housing Dataset (predict house prices)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rio);library(tidyverse)\nDataHousing =\n  import(\"https://lange-analytics.com/AIBook/Data/HousingData.csv\") %>% \n  select(Price=price, Sqft=sqft_living, Bedrooms=bedrooms,Waterfront=waterfront)\nprint(DataHousing[1:3,])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Price Sqft Bedrooms Waterfront\n1 221900 1180        3         no\n2 538000 2570        3         no\n3 180000  770        2         no\n```\n:::\n:::\n\n\n-   **Outcome Variable**: The variables that is the outcome of the prediction ($Price$)\n\n-   **Predictor Variables**: The variables that **predict** an outcome ($Sqft$, $Bedrooms$, $Waterfront$)\n\n-   **Example linear regression:** \n$$Price=\\beta_1 \\cdot Sqft+ \\beta_2 \\cdot Bedrooms +\\beta_3 \\cdot Waterfront+\\beta_4$$\n\n### Synonyms\n\n-   **Synonyms for Outcome Variable:**\n\n    ::: nonincremental\n    -   Response variable (it responds to the predictors)\n    -   Dependent variable (it is dependent on the predictors)\n    -   Endogenous variable (it is dependent on the predictors)\n    :::\n\n-   **Synonyms for Predictor Variables:**\n\n    ::: nonincremental\n    -   Explanatory variables variables (they explain the outcome)\n    -   Independent variables (they are chosen independently to see how the impact the outcome)\n    -   Exogenous variable (they are chosen independently to see how the impact the outcome)\n    :::\n:::\n\n\n## Prediction\n\n**Predicting** means that we use the values for one or more known variables to estimate an *outcome*. Predictions can be forecasts. For example if we predict tomorrows weather based on todays weather and the barometric change of pressure from today. However, *predictions* are often not forecasts. E.g., if we predict the price of a house (today) based on it's square footage (today). \n\nWe distinguish variables where we know the value from variables that we have predicted by adding a *hat* on the predicted variable. For example $Price_i$ would indicate the price of a specific house (the house $i$) that we know, while $\\widehat{Price_i}$ would indicate that the price of the house is *predicted* based on a model.\n\n\n## Model {.smaller}\n\nA *model* is what we use to predict a variable based on values of other variables, and given certain assumptions. \n\nThis sounds complicated, but can be easily explained when using an example. Suppose, we try to predict real estate prices based on the square footage of a house with ordianry least square regression, which implies that the relation beween price ($Price$) and square footage ($Sqft$) is linear and can be expressed as:\n    \n$$\\widehat{Price_i}=\\beta_1 Sqft_i + \\beta_2$$\n\n    \n## Fitted Model {.smaller}\n\nCan we use the model from the previous slide to predict the price of a house, if we know the house's square footage? YES and NO \n\nSuppose OLS  based on data determines that $\\beta_1=300$ an that $\\beta_2=500,000$ than our model would look like this:\n$$\\widehat{Price_i}=300 Sqft_i + 500000$$\n\nA model where the parameters (the $\\beta's$) have been determined by a machine learning algorithm is called a **fitted model**.\n    \n**A fitted model can be used for predictions.** E.g., a house with a square footage of 1,000 sqft is predicted to cost $8000,000 in our case: \n    \n    $$\\widehat{Price_i}=300 \\cdot 1,000 + 500,000= 800,000$$\n\n## Parameters\n  The $\\beta s$ of a model. Machine learning can be (over)simplified to the following steps:\n  \n  1. Determine the modl including the $\\beta s$ \n  \n  2. Use machine learning to determine the $\\beta s$ and therefore create a *fitted model*\n  \n  3. Use the itted model o predict based on *predictor variables*\n\n\n## Why Using R for Machine Learning?\n\nAlternatives\n\n- Phython\n- SAS\n- Stata\n- SPSS",
    "supporting": [
      "MLIntro_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n\r\n      // dispatch for htmlwidgets\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for reveal\r\n    if (window.Reveal) {\r\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\r\n        fireSlideChanged(event.previousSlide, event.currentSlide);\r\n      });\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}